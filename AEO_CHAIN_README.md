# AEO Chain Implementation

Complete implementation of the Answer Engine Optimization (AEO) evaluation chain using Google Gemini AI.

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
npm install
```

### 2. Setup Environment
```bash
cp env.example .env
# Edit .env and add your GEMINI_API_KEY
```

### 3. Test the Setup
```bash
npm run test-chain
```

### 4. Run Full AEO Analysis
```bash
npm run aeo-chain
```

### 5. View Results Dashboard
```bash
npm run dashboard
```

## ğŸ“ Project Structure

```
/Users/kjyoo/Perpex/
â”œâ”€â”€ prompts/                    # Modular system prompts
â”‚   â”œâ”€â”€ CHAIN.md               # Chain overview
â”‚   â”œâ”€â”€ schemas.json           # JSON schemas
â”‚   â”œâ”€â”€ 01_intake.md          # Intake normalization
â”‚   â”œâ”€â”€ 02_context_priming.md # Context priming
â”‚   â”œâ”€â”€ 03_scoring.md         # AEO scoring
â”‚   â”œâ”€â”€ 04_recommendations.md # Recommendations
â”‚   â””â”€â”€ sample_data/          # Sample Google & Perplexity data
â”‚       â”œâ”€â”€ google-result.json
â”‚       â””â”€â”€ perplexity-result.json
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ aeo-chain.js          # Main orchestrator
â”‚   â”œâ”€â”€ url-parser.js         # URL content extractor
â”‚   â””â”€â”€ test-chain.js         # Test runner
â”œâ”€â”€ output/                   # Generated results
â””â”€â”€ AEO Context              # AEO guide content
```

## ğŸ”§ Components

### 1. Main Orchestrator (`src/aeo-chain.js`)
- Coordinates all chain steps
- Manages Gemini API calls
- Handles JSON parsing and validation
- Saves results to `output/`

### 2. URL Parser (`src/url-parser.js`)
- Extracts content from competitor URLs
- Analyzes page structure for AEO signals
- Generates "why it ranks" hypotheses
- Rate-limited parallel processing

### 3. Chain Steps
1. **Intake Normalization**: Validates and normalizes Google/Perplexity inputs
2. **Context Priming**: Converts AEO guide into operational heuristics
3. **Scoring**: Applies AEO scorecard (100 points across 5 pillars)
4. **Recommendations**: Generates prioritized, actionable improvements

## ğŸ“Š Sample Data Analysis

The implementation uses your sample data:
- **Query**: "ìŠ¤ë§ˆíŠ¸ TV" (Smart TV)
- **Brand**: "LG"
- **Google Results**: 10 positions with brand visibility analysis
- **Perplexity Results**: Brand mentions, sentiment, competitor comparison

## ğŸ¯ Key Features

### Competitor Analysis
- Automatically extracts top-ranking URLs from Google results
- Parses competitor pages to identify AEO signals:
  - Question-based headings (H2/H3)
  - Answer-first content blocks
  - FAQ sections
  - Schema markup
  - Authority signals

### AEO Scoring (100 Points)
- **Pillar I**: On-Page Structure (15 pts)
- **Pillar II**: E-E-A-T & Content Quality (25 pts)
- **Pillar III**: Off-Site Authority & Brand Mentions (30 pts)
- **Pillar IV**: Technical Foundation & Schema (15 pts)
- **Pillar V**: Direct AEO Performance (15 pts)

### Actionable Recommendations
- Prioritized by impact/effort matrix (P0/P1/P2)
- Ready-to-use content snippets
- JSON-LD schema blocks
- Competitor-inspired improvements

## ğŸ“ˆ Output Format

Results are saved to `output/aeo-results.json`:

```json
{
  "timestamp": "2025-01-XX...",
  "brand": "LG",
  "query": "ìŠ¤ë§ˆíŠ¸ TV",
  "steps": {
    "normalizedIntake": {...},
    "aeoHeuristics": {...},
    "aeoScore": {...},
    "pageAudits": [...],
    "recommendations": {...}
  },
  "summary": {
    "totalScore": 65,
    "scoreCategory": "AEO Competitor",
    "topRecommendations": [...],
    "competitorInsights": 5
  }
}
```

## ğŸ” Example Recommendations

Based on your LG Smart TV analysis, typical recommendations include:

### P0 (High Impact, Low Effort)
- Add question-based H2: "ìŠ¤ë§ˆíŠ¸ TV ì¶”ì²œ 2025ë…„ ìµœê³  ëª¨ë¸ì€?"
- Insert 50-word answer block after each H2
- Add FAQ schema for common questions

### P1 (High Impact, Medium Effort)
- Create comprehensive comparison table (LG vs Samsung vs Sony)
- Add Product schema with specific model details
- Build authority through expert quotes and reviews

### P2 (Medium Impact, High Effort)
- Develop original research content
- Secure mentions in tech publications
- Create video content for enhanced engagement

## ğŸ›  Customization

### Adding New Prompts
1. Create new `.md` file in `prompts/`
2. Add corresponding method in `AEOChain` class
3. Update chain flow in `run()` method

### Modifying Scoring
- Edit `prompts/03_scoring.md`
- Adjust weights in AEO Context guide
- Update schema in `schemas.json`

### URL Parser Extensions
- Add new content extractors in `url-parser.js`
- Extend `PageAudit` schema
- Add domain-specific parsing logic

## ğŸ”§ Troubleshooting

### Common Issues

1. **Gemini API Errors**
   ```bash
   # Check API key
   echo $GEMINI_API_KEY
   
   # Test API directly
   npm run test-chain
   ```

2. **URL Parsing Failures**
   - Some sites block automated requests
   - Rate limiting may cause timeouts
   - Check console for specific error messages

3. **JSON Parsing Errors**
   - Gemini sometimes returns malformed JSON
   - The parser attempts to extract from markdown blocks
   - Check raw responses in console output

### Performance Optimization

- **Parallel Processing**: URL parsing uses batched requests (3 concurrent)
- **Rate Limiting**: 1-second delays between batches
- **Caching**: Consider adding Redis for repeated analyses
- **Streaming**: Gemini responses are streamed for better UX

## ğŸ“š Next Steps

1. **Run Analysis**: Execute the chain on your sample data
2. **Review Results**: Check `output/aeo-results.json`
3. **Implement Recommendations**: Apply P0 suggestions first
4. **Monitor Progress**: Re-run analysis after changes
5. **Scale Up**: Add more queries and competitors

## ğŸ¤ Integration

The modular design allows easy integration with:
- **CMS Systems**: Automated content optimization
- **SEO Tools**: Bulk analysis workflows  
- **Monitoring**: Scheduled AEO health checks
- **Reporting**: Dashboard integrations

---

**Ready to improve LG's AEO performance for "ìŠ¤ë§ˆíŠ¸ TV" queries!** ğŸš€
